\documentclass[preprint2,numberedappendix,tighten,twocolappendix]{aastex6}  % USE THIS TO MAKE BIB, THEN FORMAT USING EMULATEAPJ
%\documentclass[twocolumn,apj,numberedappendix]{emulateapj}
\shorttitle{Epoch of Reionization Power Spectrum Results from PAPER-128}
\shortauthors{Cheng}

\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[figuresright]{rotating}
\usepackage{natbib}
\usepackage{ctable}
\citestyle{aa}

%		Math Shortcuts from Adrian
%\def\b{\mathbf{b}}
%\def\k{\mathbf{k}}
%\def\r{\mathbf{r}}
%\def\q{\mathbf{q}}
%\def\b{\mathbf{b}}
%\def\kp{\mathbf{k}^\prime}
%\def\kpp{\mathbf{k}^{\prime\prime}}
%\def\V{\mathbb{V}}
%\def\At{\tilde{A}}
%\def\Vt{\tilde{V}}
%\def\Tt{\tilde{T}}
%\def\tb{\langle T_b\rangle}
%\newcommand{\vis}{\mathbf{v}}
%\newcommand{\x}{\mathbf{x}}
%\newcommand{\xhat}{\hat{\mathbf{x}}}
%\newcommand{\nhat}{\hat{\mathbf{n}}}
%\newcommand{\A}{\mathbf{A}}
%\newcommand{\N}{\mathbf{N}}
%\newcommand{\rhat}{\hat{\mathbf{r}}}
%\newcommand{\khat}{\hat{\mathbf{k}}}
%\newcommand{\btheta}{\boldsymbol \theta}

\newcommand{\cc}[1]{{\color{purple} \textbf{[#1]}}}

\begin{document}
\title{Epoch of Reionization Power Spectrum Results from PAPER-128}

\author{
%Aaron R. Parsons\altaffilmark{1,2},
%Adrian Liu\altaffilmark{1,2},
%James E. Aguirre\altaffilmark{3},
%Zaki S. Ali\altaffilmark{1},
Carina Cheng\altaffilmark{1}
%Daniel C. Jacobs\altaffilmark{8},
%David F. Moore\altaffilmark{3},
%Jonathan C. Pober\altaffilmark{1},
}


%		Notes	
	
%Reference section with: \ref{sec:Intro}
%Reference equation with: \eqref{eq:eqtest}
%Reference figure with: \ref{fig:figtest}
%Cite paper inside sentence: \citet{ref}
%Cite paper at end of sentence: \citep{ref}
%Cite paper inside a parenthetical sentence: \citealt{ref}

%To compile with references shown, compile in BibTeX once and LaTeX twice


%		Sample Equation Syntax
%\begin{equation}
%\label{eqtest}
%\langle \widetilde{T} (\mathbf{k}) \widetilde{T}^* (\mathbf{k^\prime}) \rangle = (2 \pi)^3 \delta^D (\mathbf{k} - \mathbf{k}^\prime) P(k),
%\end{equation}


\altaffiltext{1}{Astronomy Dept., U. California, Berkeley, CA}
%\altaffiltext{2}{Hubble Fellow}
%\altaffiltext{2}{Radio Astronomy Lab., U. California, Berkeley, CA}
%\altaffiltext{3}{Berkeley Center for Cosmological Physics, Berkeley, CA}
%\altaffiltext{3}{Dept. of Physics and Astronomy, U. Pennsylvania, Philadelphia, PA}
%\altaffiltext{8}{School of Earth and Space Exploration, Arizona State U., Tempe, AZ}

\begin{abstract}
\end{abstract}


\section{Introduction}
\label{sec:Intro}

\cc{Need to cite papers...}

The Epoch of Reionization (EoR) represents an uncharted phase in cosmic history when the first stars and galaxies ionized the neutral hydrogen present in the early Universe. During this time, it is believed that baryonic matter fell into dark matter potential wells, gravitationally collapsing into the first luminous structures. These sources, possibly quasars or young dwarf galaxies, emit radiation that ionized the abundant hydrogen in the intergalactic medium (IGM). The subsequent formation of a web of galaxies across an ionized IGM is thought to represent the large scale structure that we observe today.

The EoR has not yet been directly detected. However, constraints have been made on its timing and duration through different methods. As reionization progressed, the number of free electrons susceptible to Thompson scattering increased, resulting in scattered cosmic microwave background (CMB) photons whose imprint has been left on CMB observations. In particular, the Thompson scattering optical depth parameter $\tau$ is a useful metric for characterizing the duration of reionization. Recent Planck measurements of $\tau$ suggest a late reionization history, occurring between redshifts of $7.7$ and $8.7$.

Galaxy observations have also begun to place constraints on the EoR. With their high luminosities, quasars make for powerful probes of the state of the IGM through absorption line studies. As photons from a quasar are redshifted, they may be absorbed by neutral hydrogen at the Lyman-$\alpha$ line, producing Gunn-Peterson trough features in quasar spectra. Observations of these spectra in high redshift galaxies have signaled the end of reionization by $z ~ 6$, and experiments are continuously pushing galaxy observations to higher redshifts. 

A third powerful probe of the EoR makes use of the $21 cm$ wavelength emission produced by hydrogen due to its two quantum states. Because hydrogen is so pervasive in the Universe and a transition from its spin up state to spin down state gives off a  well-defined energy difference in the form of a $21 cm$ wavelength photon, observations targeting this signal have the potential to trace the EoR from start to finish. However, $21 cm$ experiments face major challenges, including those from bright foregrounds and instrumental systematics. Nevertheless, the observations and analyses of data from current radio telescope arrays have already begun to constrain the $21 cm$ signal and make statements about the nature of the IGM during the EoR. 

Major existing $21 cm$ experiments include both those targeting to measure the sky-averaged `global' $21 cm$ signal and those employing interferometric elements and the use of cross-correlations and statistical power-spectral measurements. Examples of the former are EDGES, the LWA, LEDA, DARE, BigHorns, and SARAS. Major interferometers include the GMRT, LOFAR, the MWA, the 21CMA, and PAPER.

In this paper we present results from the $128$ antenna configuration of the Donald C. Baker Precision Array for Probing the Epoch of Reionization (PAPER). PAPER is a highly redundant array consisting of dual-polarization dipole antennas. Its configuration is optimal for boosting power spectrum sensitivity and the analysis used relies on a foreground avoidance approach where we measure power spectrum values in a region of delay space that is uncontaminated by foregrounds. Previous upper limits on the EoR power spectrum include those made by PAPER-32, which used its redundant configuration to its advantage to obtain an upper limit of $\Delta^{2}(k) \leq (41 mk)^{2}$ at $k=0.28h Mpc^{-2}$. Doubling in array size and employing an updated analysis pipeline that included fringe-rate filtering and an optimal quadratic estimator framework for the power spectrum analysis achieved an upper limit on $\Delta^{2}(k)$ of $(22.4 mK)^{2}$ in the range $0.15 < k < 0.5h Mpc^{-1}$ at $z = 8.4$. The result from PAPER-64 was the best published upper limit thus far, with PAPER-128 achieving a factor of ?? in improvement.

PAPER-128 has been able to use much of the same technical analysis framework from previous PAPER analyses, while improving on the limits set by PAPER-64 with a longer observing time, double the number of antennas, and the development of new data quality tests, signal loss simulations, and inverse covariance weighting techniques. 

The organization of the paper is as follows. ...

\section{Observations}
\label{sec:Obs}

\begin{figure*}[!]
	\centering
	\includegraphics[width=1.0\textwidth]{antlayout.png}
	\caption{The antenna layout of PAPER-128. Core grid antennas are labeled $1$ through $111$ and outrigger antennas are labeled $112$ through $127$.}
	\label{fig:layout}
\end{figure*}

PAPER is located in the Karoo desert in South Africa at a latitude of $-30:43:18$ and longitude of $21:25:42$. The PAPER-128 antenna configuration is shown in \ref{fig:layout}. It consists of a $7$x$16$ core grid of antennas and $16$ outrigger antennas, some of which are located inside the core grid and some placed farther away to establish longer baselines. The analysis carried out in this paper makes use of only the core grid of antennas, with the East-West direction shown in \ref{fig:layout} as to the right and left. Adjacent East-West baselines have a length of $15 m$ and adjacent North-South baselines have a length of $4 m$. The baselines used in our analysis are...

The PAPER signal chain consists of drift-scan antenna elements...
The PAPER beam is...

The PAPER-128 observing season began in November, 2013, with nightly data taken for approximately $4$ months. The second observing season started up again in June, 2014 and lasted until February, 2015. Both these seasons encompass part or all of the months corresponding to our optimal observing season for which the Galaxy is below the horizon. Collectively, PAPER-128 logged $233$ nights of raw data. In this analysis, we use $??$ nights of data from season $??$. We exclude nights of known hardware malfunctioning (power failures, overheating of equipment, etc.), as well as outlier nights whose data did not pass our quality checks (see: quality paper). For our analysis, we use an LST range of $??$ which corresponds to observations of a `cold patch' of the night sky. All polarization products are saved, but we only make use of the XX and YY polarizations in this paper.

\section{Data Reduction}
\label{sec:Cal}

Raw PAPER data consists of $1024$ frequency channels sampled every $97.6 kHz$. Every $10$ minute file then goes through our compression pipeline, which consists of a two-step radio frequency interference (RFI) flagger and averaging along both the frequency (delay filtering) and time (fringe rate filtering) axes. Final compressed data consists of $203$ frequency channels covering a bandwidth of $100-200 MHz$. Each $10$ minute file contains data sampled at integrations of $31.65 s$. The amplitudes of one night of raw and compressed data is shown in \ref{fig:raw} as waterfall plots of frequency versus time. 

\begin{figure*}[!]
	\centering
	%\includegraphics[width=1.0\textwidth]{raw.png}
	\caption{Waterfall plots (in log Janskys) of one night of raw PAPER-128 data (left) and the same data after compression (right). Compression downsizes files by averaging over time and frequency and flags radio frequency interference.}
	\label{fig:raw}
\end{figure*}

\subsection{Redundant Calibration}

The sought-after $21 cm$ signal lies beneath bright foregrounds and various instrumental systematics that contaminate our data. Because foregrounds are predicted to be $4-5$ orders of magnitude brighter than the cosmological signal, $21 cm$ experiments require high dynamic ranges and considerable sensitivities. PAPER is designed to boost its sensitivity by containing many short, repeated baselines of the same length and orientation in its array. Thus, PAPER is able to measure the same Fourier-mode on the sky multiple times while beating down the amount of noise with each successive measurement.

Calibration of antennas in a redundant array is therefore crucial in order to maximize sensitivity. In our raw data, visibility measurements from two identical baseline types are not necessarily equal. This is due to changing system temperatures and different signal chains as data flows from each antenna into the correlator. However, PAPER's redundant layout can be used to solve for complex antenna gains, which when applied to the data, bring all visibility measurements for a specific baseline type into alignment. 

Redundant calibration has proven to be a powerful tool. PAPER-64 relied on redundant calibration to achieve its power spectrum limits, and here we update our method and tools and apply it to PAPER-128. As a review, let's start with the visibility measurement equation:

\begin{eqnarray}
\label{viseq}
V_{ij}' &=& g_{i}^{*}g_{j}V_{ij} + n_{ij} \\
g_{j} &=&\eta_{j} + i\phi_{j}
\end{eqnarray}

Here $V_{ij}'$ represents a measured visibility for a baseline with antennas $i$ and $j$, $V_{ij}$ represents the `true' sky visibility for that same baseline, $g_{i}$ and $g_{j}$ are the complex gain factors for each antenna, and $n_{ij}$ is noise. Each gain number consists of an amplitude $\eta$ and phase $\phi$. The visibility equation can be written down for all baselines and - without using array redundancy - would not be least squares solvable because the number of unknowns ($2N+N(N-1)/2$) is greater than the number of measurements ($N(N-1)/2$), where $N$ is the number of antennas . However, if $V_{ij}$, the `true', or `model' visibility, is constrained to be the same for all identical baselines, the system of equations becomes solvable.

For our analysis, we use the package Omnical for redundant calibration. Similarly to the analysis of PAPER-64, Omnical comprises of three steps. The first is $FirstCal$, which uses all baseline redundancies to generate a static gain solution for each antenna that will unwrap any phase wrapping between two identical baselines. We perform $FirstCal$ because the next stage of Omnical cannot tell the difference between a phase of $0$ and $2\pi$, for example. The second step is $LogCal$, which takes the log of all the visibility equations and separates the real and imaginary components into two matrices. Coarse solutions are determined for both the antenna gains and `model' visibilities (one for each baseline type) simultaneously. The final step of Omnical is $LinCal$, which applies small perturbations to the $LogCal$ solutions in an iterative fashion, honing in on the optimal solutions.

We perform redundant calibration for each epoch of data used in our analysis, as each epoch has to be separately calibrated since they are on different overall gain scales. We divide out the antenna gains for each of our measured visibilities, bringing them into alignment with each other (for identical baseline types) and the `model' visibility for that baseline type. We also include the subtraction of crosstalk in our dataset. Crosstalk shows up as a constant signal in time in our visibilities and is attributed to signals from one antenna being picked up by another. Omnical handles crosstalk by subtracting off an averaged residual (differences between measured visibilities and the `model' visibility, averaged over baseline type) for each visibility measurement.

For PAPER-128, we update the Omnical software package, originally written in C, with a user-friendly interface written in Python.  Additionally, we employ a chi-square metric on a per antenna basis in order to exclude dead or faulty antennas and improve our calibration solutions. \cc{Add plots to show stability of Omnical solutions and chi-square examples}
 
It is important to note that while Omnical is powerful for ensuring array redundancy, it is not able to solve for $4$ calibration parameters - namely, to correct for the overall gain, phase, and tip/tilt of the array. In order to do this, we turn to...

\subsection{Bandpass Calibration}

\subsection{Delay-Domain Foreground Removal}

Foregrounds pose a significant challenge to EoR experiments. Some experiments, like LOFAR and the MWA, rely on modeling and foreground subtraction to create a clean EoR `window' in which to make their power spectrum measurements. Previous PAPER results, including this one, instead focus on a foreground avoidance approach. 

In order to filter foregrounds, we exploit their spectrally-smooth nature. By Fourier-transforming our visibilities along the frequency axis, the delay domain provides a natural space in which to isolate foregrounds. Physically, a time delay can be thought of as the extra time light from a source takes to reach one antenna compared to another one (due to slightly different traveling distances). The maximum delay a source on the sky can have is if it is located on the horizon. In this case, the delay is determined by the length of the baseline. Consequently, all spectrally-smooth foreground signals show up within a maximum delay (or `horizon limit') given a baseline length. The EoR signal, however, is believed to mimic noise which has a random frequency structure and is not confined to be within the horizon limit. A simple way to avoid foregrounds without removing the cosmological signal, therefore, is to make our power spectrum measurements outside of the horizon limit that contains the bright foregrounds. 

In practice, we filter our calibrated visibilities by de-convolving out our sampling function (which contains flags due to RFI) from our delay-domain visibilities using a CLEAN-like algorithm and restricting our clean components to inside the horizon limit (set by the baseline length) plus a $15 ns$ buffer. The Fourier-transformed clean components are then subtracted from our visibilities. This filtering process is performed on a per-baseline, per-integration basis, and we achieve a brightness suppression of $~2$ orders of magnitude in our visibilities. 

\subsection{RFI Removal and LST-Binning}

\subsection{Absolute Calibration}

\section{Power Spectrum Analysis}
\label{sec:PS}

\subsection{Optimal Quadratic Estimators}
\label{sec:OQE}

\subsection{Signal Loss}
\label{sec:Sigloss}

\section{Results}
\label{sec:Res}

\section{Conclusions}
\label{sec:Con}

\section{Acknowledgements}
\label{sec:Ack}

\bibliographystyle{apj}
\bibliography{refs}


\end{document}

